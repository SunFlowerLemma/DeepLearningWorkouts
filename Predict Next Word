{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMpogDvDlj1ldAXc0LTpHTO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SunFlowerLemma/DeepLearningWorkouts/blob/master/Predict%20Next%20Word\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9zo8QXtvTeH",
        "outputId": "318cc1a3-42b3-4b34-9245-f3b72cfe0696"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://homl.info/shakespeare\n",
            "1115394/1115394 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "shakespeare_url = \"https://homl.info/shakespeare\"  \n",
        "filepath = tf.keras.utils.get_file(\"shakespeare.txt\", shakespeare_url)\n",
        "with open(filepath) as f:\n",
        "    shakespeare_text = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(shakespeare_text[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qH7m_v5HvW-8",
        "outputId": "7c965c1a-c2c8-407e-b2d8-cb4f779c9ca7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_vec_layer = tf.keras.layers.TextVectorization(split=\"character\",\n",
        "                                                   standardize=\"lower\")\n",
        "text_vec_layer.adapt([shakespeare_text])\n",
        "encoded = text_vec_layer([shakespeare_text])[0]"
      ],
      "metadata": {
        "id": "AbQvCPlmvho4"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded -= 2  \n",
        "n_tokens = text_vec_layer.vocabulary_size() - 2  \n",
        "dataset_size = len(encoded)  "
      ],
      "metadata": {
        "id": "5a9eNRw-1JsE"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def to_dataset(sequence, length, shuffle=False, seed=None, batch_size=32):\n",
        "    ds = tf.data.Dataset.from_tensor_slices(sequence)\n",
        "    ds = ds.window(length + 1, shift=1, drop_remainder=True)\n",
        "    ds = ds.flat_map(lambda window_ds: window_ds.batch(length + 1))\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(buffer_size=100_000, seed=seed)\n",
        "    ds = ds.batch(batch_size)\n",
        "    return ds.map(lambda window: (window[:, :-1], window[:, 1:])).prefetch(1)"
      ],
      "metadata": {
        "id": "JMu-_QIK1N7U"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "length = 100\n",
        "tf.random.set_seed(42)\n",
        "train_set = to_dataset(encoded[:1_000_000], length=length, shuffle=True,\n",
        "                       seed=42)\n",
        "valid_set = to_dataset(encoded[1_000_000:1_060_000], length=length)\n",
        "test_set = to_dataset(encoded[1_060_000:], length=length)"
      ],
      "metadata": {
        "id": "n50liZLI1SGB"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=n_tokens, output_dim=16),\n",
        "    tf.keras.layers.GRU(128, return_sequences=True),\n",
        "    tf.keras.layers.Dense(n_tokens, activation=\"softmax\")\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model_ckpt = tf.keras.callbacks.ModelCheckpoint(\n",
        "    \"my_shakespeare_model\", monitor=\"val_accuracy\", save_best_only=True)\n",
        "history = model.fit(train_set, validation_data=valid_set, epochs=10,\n",
        "                    callbacks=[model_ckpt])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGQ1-5wN1WHj",
        "outputId": "15500e07-88e4-42a3-8c2f-4b3e754ab453"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "  20779/Unknown - 2374s 113ms/step - loss: 1.4152 - accuracy: 0.5690"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shakespeare_model = tf.keras.Sequential([\n",
        "    text_vec_layer,\n",
        "    tf.keras.layers.Lambda(lambda X: X - 2),  # no <PAD> or <UNK> tokens\n",
        "    model\n",
        "])"
      ],
      "metadata": {
        "id": "BVnYkX3F1X-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_proba = shakespeare_model.predict([\"All the life is a s\"])[0, -1]"
      ],
      "metadata": {
        "id": "IKtCPzhH1Z0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = tf.argmax(y_proba)"
      ],
      "metadata": {
        "id": "xHQQ9kBw1cIY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_vec_layer.get_vocabulary()[y_pred + 2]"
      ],
      "metadata": {
        "id": "wEEYRECf1dka"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}